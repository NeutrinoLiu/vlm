{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcdb7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working dir /mnt/bn/nlhei-nas/liubangya/proj/vlm/QA\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.chdir(\"/mnt/bn/nlhei-nas/liubangya/proj/vlm/QA\")\n",
    "print(f\"current working dir\", os.getcwd())\n",
    "\n",
    "# function pool here\n",
    "from templates_lib.filter import *\n",
    "from templates_lib.func import *\n",
    "from templates_lib.QA import QADataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6ba56",
   "metadata": {},
   "source": [
    "### Static::Measurement::object_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1c2a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ef91953714a5ab74be38bb0a6360f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DS_ROOT = \"./structured-data\"\n",
    "TEST_SPLIT = 0.2\n",
    "CAP_FILE = \"captions_all.yaml\"\n",
    "\n",
    "random.seed(0)\n",
    "myCap = Captioner(CAP_FILE)\n",
    "ds = QADataset(DS_ROOT, myCap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970cc65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"image_nohint_9x16_4\": {\n",
      "        \"train_qa\": \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_4/pairs/QA_pairs_qwen.train.json\",\n",
      "        \"test_qa\": \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_4/pairs/QA_pairs_qwen.test.json\",\n",
      "        \"train_qa_meta\": \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_4/pairs/QA_pairs.train.json\",\n",
      "        \"test_qa_meta\": \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_4/pairs/QA_pairs.test.json\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from templates_lib.task import MultiTaskSet\n",
    "from templates_lib.task.distance_tasks import DistTasks\n",
    "from templates_lib.task.movement_tasks import MovementTasks\n",
    "from templates_lib.task.grid_tasks import GridIndexTasks\n",
    "from templates_lib.task.tracking_tasks import TrackingTasks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tasks_cfg = {\n",
    "    \"total_QAs\": 6000,\n",
    "    \"roi_frame_only\": True,\n",
    "    \"H\": 900, \"W\": 1600, \"patchsize_H\": 100, \"patchsize_W\": 100,\n",
    "    \"motion_thres\": 4, \"num_frame\": 4\n",
    "}\n",
    "\n",
    "\n",
    "total_qas = tasks_cfg[\"total_QAs\"]\n",
    "H_grids = tasks_cfg[\"H\"] // tasks_cfg[\"patchsize_H\"]\n",
    "W_grids = tasks_cfg[\"W\"] // tasks_cfg[\"patchsize_W\"]\n",
    "# task_dir = f\"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/grid_idx_{H_grids}x{W_grids}\"\n",
    "task_dir = f\"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_{H_grids}x{W_grids}_{tasks_cfg['num_frame']}\"\n",
    "OUTPUT_DIR = os.path.join(task_dir, \"pairs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_QWEN = f\"{OUTPUT_DIR}/QA_pairs_qwen.json\"\n",
    "OUTPUT_JSON = f\"{OUTPUT_DIR}/QA_pairs.json\"\n",
    "\n",
    "task_obj = {\n",
    "    os.path.basename(task_dir): {\n",
    "        \"train_qa\": OUTPUT_QWEN.replace(\".json\", \".train.json\"),\n",
    "        \"test_qa\": OUTPUT_QWEN.replace(\".json\", \".test.json\"),\n",
    "        \"train_qa_meta\": OUTPUT_JSON.replace(\".json\", \".train.json\"),\n",
    "        \"test_qa_meta\": OUTPUT_JSON.replace(\".json\", \".test.json\"),\n",
    "    }\n",
    "}\n",
    "print(json.dumps(task_obj, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 QAs, stats: {'obj_cross_frame_tracking': 500}\n",
      "Generated 1000 QAs, stats: {'obj_cross_frame_tracking': 1000}\n",
      "Generated 1500 QAs, stats: {'obj_cross_frame_tracking': 1500}\n",
      "Generated 2000 QAs, stats: {'obj_cross_frame_tracking': 2000}\n",
      "Generated 2500 QAs, stats: {'obj_cross_frame_tracking': 2500}\n",
      "Generated 3000 QAs, stats: {'obj_cross_frame_tracking': 3000}\n",
      "Generated 3500 QAs, stats: {'obj_cross_frame_tracking': 3500}\n",
      "Generated 4000 QAs, stats: {'obj_cross_frame_tracking': 4000}\n",
      "Generated 4500 QAs, stats: {'obj_cross_frame_tracking': 4500}\n",
      "Generated 5000 QAs, stats: {'obj_cross_frame_tracking': 5000}\n",
      "Generated 5500 QAs, stats: {'obj_cross_frame_tracking': 5500}\n",
      "Generated 6000 QAs, stats: {'obj_cross_frame_tracking': 6000}\n",
      "total 6000 qas\n",
      "stats: {\n",
      "  \"obj_cross_frame_tracking\": 6000\n",
      "}\n",
      "total objects: 2707\n",
      "total scenes: 759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myfilter = filter_all(\n",
    "    filter_visiblity,\n",
    "    filter_area_fn(1e4, 4e5),\n",
    "    black_list_fn([\n",
    "            \"movable_object.trafficcone\",\n",
    "            \"movable_object.barrier\",\n",
    "        ])\n",
    "    )\n",
    "\n",
    "# taskset = MultiTaskSet(\n",
    "#     subsets=[DistTasks, MovementTasks],\n",
    "#     captioner=myCap,\n",
    "#     basefilter=myfilter,\n",
    "#     cfg=tasks_cfg)\n",
    "\n",
    "# taskset = GridIndexTasks(\n",
    "#     H = 900, W = 1600, patchsize_H = 100, patchsize_W = 100,\n",
    "#     captioner=myCap,\n",
    "#     basefilter=myfilter,\n",
    "#     cfg=tasks_cfg\n",
    "# )\n",
    "\n",
    "taskset = TrackingTasks(\n",
    "    captioner=myCap,\n",
    "    basefilter=myfilter,\n",
    "    cfg=tasks_cfg\n",
    ")\n",
    "\n",
    "\n",
    "qas, stats = taskset.produce(\n",
    "    dataset=ds,\n",
    "    num_qas=total_qas,\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "print(f\"total {len(qas)} qas\")\n",
    "print(f\"stats: {json.dumps(stats, indent=2)}\")\n",
    "\n",
    "all_dumps = [qa.dump() for qa in qas]\n",
    "content_stats = {\n",
    "    \"objs\": set(),\n",
    "    \"scenes\": set(),\n",
    "}\n",
    "for qa in all_dumps:\n",
    "    content_stats[\"objs\"].update(qa[\"objs\"])\n",
    "    content_stats[\"scenes\"].update([qa[\"scene\"]])\n",
    "print(f\"total objects: {len(content_stats['objs'])}\")\n",
    "print(f\"total scenes: {len(content_stats['scenes'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3af082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_test = int(len(qas) * TEST_SPLIT)\n",
    "qas_train = qas[:-num_test]\n",
    "qas_test = qas[-num_test:]\n",
    "\n",
    "all_frames = not taskset.cfg[\"roi_frame_only\"]\n",
    "\n",
    "with open(OUTPUT_QWEN.replace(\".\", \".test.\"), \"w\") as f:\n",
    "    qas_dumps = [qa.qwen_format(all_frames=all_frames) for qa in qas_test]\n",
    "    for i, qa in enumerate(qas_dumps):\n",
    "        qa[\"id\"] = i\n",
    "    json.dump(\n",
    "        qas_dumps, f, indent=2\n",
    "    )\n",
    "with open(OUTPUT_QWEN.replace(\".\", \".train.\"), \"w\") as f:\n",
    "    qas_dumps = [qa.qwen_format(all_frames=all_frames) for qa in qas_train]\n",
    "    for i, qa in enumerate(qas_dumps):\n",
    "        qa[\"id\"] = i\n",
    "    json.dump(\n",
    "        qas_dumps, f, indent=2\n",
    "    )\n",
    "with open(OUTPUT_JSON.replace(\".\", \".test.\"), \"w\") as f:\n",
    "    qas_dumps = [qa.dump() for qa in qas_test]\n",
    "    for i, qa in enumerate(qas_dumps):\n",
    "        qa[\"id\"] = i\n",
    "    json.dump(qas_dumps, f, indent=2)\n",
    "with open(OUTPUT_JSON.replace(\".\", \".train.\"), \"w\") as f:\n",
    "    qas_dumps = [qa.dump() for qa in qas_train]\n",
    "    for i, qa in enumerate(qas_dumps):\n",
    "        qa[\"id\"] = i\n",
    "    json.dump(qas_dumps, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "fileId": "5e024d9d-3d83-4fc8-b52d-d080fd5172bb",
  "filePath": "/mnt/bn/nlhei-nas/liubangya/proj/vlm_proj/QA/templating-naive.ipynb",
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
