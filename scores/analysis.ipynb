{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abccaefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78e22784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def load_ans(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "    return data\n",
    "def json_unwrap(s_raw, as_list= False):\n",
    "    \n",
    "    # cut s with left most { and right most }, included\n",
    "    if as_list:\n",
    "        s = s_raw[s_raw.find(\"[\"):s_raw.rfind(\"]\")+1]\n",
    "    else:\n",
    "        s = s_raw[s_raw.find(\"{\"):s_raw.rfind(\"}\")+1]\n",
    "    # print(s)\n",
    "\n",
    "    if s.startswith(\"```json\"):\n",
    "        s = s[7:]\n",
    "    elif s.startswith(\"```\"):\n",
    "        s = s[3:]\n",
    "    if s.endswith(\"```\"):\n",
    "        s = s[:-3]\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        # print(f\"fail to parse json: {s_raw} -> {s}\")\n",
    "        raise\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d421777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerify(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            try:\n",
    "                d[k] = float(v)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return d\n",
    "\n",
    "def complete_check(gt, pred):\n",
    "    for k in gt:\n",
    "        if k not in pred:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def norm_error(gt, pred):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    pred = numerify(pred)\n",
    "    dist = sum(\n",
    "        (gt[k] - pred[k]) ** 2 for k in gt\n",
    "    )\n",
    "    gt_norm = sum(\n",
    "        (gt[k] ** 2) for k in gt\n",
    "    )\n",
    "    return min( dist / gt_norm, 1.0 )\n",
    "\n",
    "def thres_error(gt, pred, thres=.5):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    pred = numerify(pred)\n",
    "    inbound = [\n",
    "        abs((gt[k] - pred[k]) / (gt[k] + 1e-5)) < thres for k in gt\n",
    "    ]\n",
    "\n",
    "    # print(f\"gt: {gt}, pred: {pred}, error: {0 if all(inbound) else 1}\")\n",
    "\n",
    "    return 0 if all(inbound) else 1\n",
    "\n",
    "def identity_error(gt, pred):\n",
    "    # print(f\"gt: {gt}, pred: {pred}\")\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    same = [\n",
    "        gt[k] == pred[k] for k in gt\n",
    "    ]\n",
    "    return 0 if all(same) else 1\n",
    "\n",
    "def norm2_error(gt, pred):\n",
    "    if not complete_check(gt, pred):\n",
    "        return 1\n",
    "    pred = numerify(pred)\n",
    "    dist = sum(\n",
    "        (gt[k] - pred[k]) ** 2 for k in gt\n",
    "    )\n",
    "    return math.sqrt(dist)\n",
    "\n",
    "per_frame_error = {}\n",
    "bad_prediction = 0\n",
    "per_frame_stand_still = {}\n",
    "total_error_stand_still_list = []\n",
    "def patch_frame_error(gt, pred, frame_bias=0):\n",
    "    global per_frame_error\n",
    "    global bad_prediction\n",
    "    global total_error_stand_still_list\n",
    "    gt_indexed = {}\n",
    "    pred_indexed = {}\n",
    "    for gt_item in gt:\n",
    "        gt_indexed[gt_item[\"frame\"]] = (gt_item[\"row\"], gt_item[\"col\"])\n",
    "    for pred_item in pred:\n",
    "        new_idx = int(pred_item[\"frame\"]) - frame_bias\n",
    "        pred_indexed[new_idx] = (pred_item[\"row\"], pred_item[\"col\"])\n",
    "\n",
    "    # print(f\"gt: {gt_indexed}, pred: {pred_indexed}\")\n",
    "    error_per_frame = 1. / len(gt_indexed)\n",
    "    error_total = 0.\n",
    "    max_deviation = 5.\n",
    "    preds = set()\n",
    "    total_error_stand_still = 0.\n",
    "    for frame in gt_indexed:\n",
    "        still_0 = list(gt_indexed.values())[0]\n",
    "        still_patch = gt_indexed[frame]\n",
    "        still_error = math.sqrt((still_0[0]-still_patch[0])**2 + (still_0[1]-still_patch[1])**2) / max_deviation\n",
    "        still_error = min(still_error, 1.0)\n",
    "        per_frame_stand_still.setdefault(frame, []).append(still_error)\n",
    "        total_error_stand_still += still_error * error_per_frame\n",
    "\n",
    "        if frame not in pred_indexed:\n",
    "            error = 1.0\n",
    "        else:\n",
    "            gt_patch = gt_indexed[frame]\n",
    "            pred_patch = pred_indexed[frame]\n",
    "            error = math.sqrt((gt_patch[0]-pred_patch[0])**2 + (gt_patch[1]-pred_patch[1])**2) / max_deviation\n",
    "            preds.add((pred_patch[0], pred_patch[1]) )\n",
    "        error = min(error, 1.0)\n",
    "        per_frame_error.setdefault(frame, []).append(error)\n",
    "        error_total += error * error_per_frame\n",
    "    if len(preds) == 1:\n",
    "        bad_prediction += 1\n",
    "    \n",
    "    total_error_stand_still_list.append(total_error_stand_still)\n",
    "    return error_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "456177df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"obj_cross_frame_tracking\": {\n",
      "        \"num_qa\": 400,\n",
      "        \"errors\": 168.94992727350015\n",
      "    }\n",
      "}\n",
      "parse fail: 0\n",
      "calc fail: 2\n",
      "Bad prediction: 4982\n",
      "Overall error: 0.4224\n",
      "Overall score: \n",
      "   0.5776\n",
      "stand still ref: 0.5933\n",
      "perframe score:\n",
      "0: 0.9917\n",
      "0 stand still : 1.0000\n",
      "1: 0.4005\n",
      "1 stand still : 0.3847\n",
      "2: 0.3601\n",
      "2 stand still : 0.3592\n",
      "3: 0.1590\n",
      "3 stand still : 0.1538\n"
     ]
    }
   ],
   "source": [
    "QA_meta = \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_2/pairs/QA_pairs.test.json\"\n",
    "ans_all = \"/mnt/bn/nlhei-nas/liubangya/proj/vlm-found3d/tasks/image_nohint_9x16_2/results/ans_lora.json\"\n",
    "\n",
    "# ans_all = \"/mnt/bn/nlhei-nas/liubangya/proj/vlm/qwen/eval/ans_video_sft.json\"\n",
    "\n",
    "popular_error = thres_error\n",
    "\n",
    "QA_meta = load_meta(QA_meta)\n",
    "ans_all = load_ans(ans_all)\n",
    "judger = {\n",
    "    \"single_obj_abs_dist\": popular_error,\n",
    "    \"double_obj_abs_dist\": popular_error,\n",
    "    \"single_obj_minmax_dist\": popular_error,\n",
    "    \"double_obj_minmax_dist\": popular_error,\n",
    "    \"multiple_obj_relative_dist\": identity_error,\n",
    "    \"local_coords\": popular_error,\n",
    "    \"obj_cross_frame_tracking\": patch_frame_error,\n",
    "    \"grid_indexing\": identity_error\n",
    "}\n",
    "\n",
    "score = {}\n",
    "dists = []\n",
    "parse_fail = 0\n",
    "calc_fail = 0\n",
    "for meta, gt in zip(QA_meta, ans_all):\n",
    "    task_type = meta[\"QA_type\"]\n",
    "    if task_type not in score:\n",
    "        score[task_type] = {\n",
    "            \"num_qa\": 0,\n",
    "            \"errors\": 0,\n",
    "        }\n",
    "\n",
    "    if task_type in judger:\n",
    "        j_func = judger[task_type]\n",
    "    else:\n",
    "        j_func = identity_error\n",
    "\n",
    "    # parse into metric json\n",
    "    try:\n",
    "        gt_ans = json_unwrap(gt[\"gt_ans\"], True)\n",
    "        pred_ans = json_unwrap(gt[\"ans\"], True)\n",
    "    except json.JSONDecodeError:\n",
    "        # print(f\"error in parse answers: {gt['ans']} {gt['gt_ans']}\")\n",
    "        score[task_type][\"errors\"] += 1.\n",
    "        score[task_type][\"num_qa\"] += 1\n",
    "        parse_fail += 1\n",
    "        continue\n",
    "\n",
    "    # evaluate the error\n",
    "    try:\n",
    "        error = j_func(gt_ans, pred_ans)\n",
    "    except Exception as e:\n",
    "        calc_fail += 1\n",
    "        # print(f\"Error in task eval {task_type}: {e}\")\n",
    "        # print(f\"gt_ans: {gt_ans}\")\n",
    "        # print(f\"pred_ans: {pred_ans}\")\n",
    "    score[task_type][\"errors\"] += error\n",
    "    score[task_type][\"num_qa\"] += 1\n",
    "\n",
    "\n",
    "print(json.dumps(score, indent=4))\n",
    "\n",
    "overall = 0.\n",
    "for k, v in score.items():\n",
    "    if v[\"num_qa\"] > 0:\n",
    "        overall += v[\"errors\"] / v[\"num_qa\"]\n",
    "\n",
    "print(f\"parse fail: {parse_fail}\")\n",
    "print(f\"calc fail: {calc_fail}\")\n",
    "print(f\"Bad prediction: {bad_prediction}\")\n",
    "print(f\"Overall error: {overall / len(score):.4f}\")\n",
    "print(f\"Overall score: \\n   {1 - overall / len(score):.4f}\")\n",
    "print(f\"stand still ref: {1 - sum(total_error_stand_still_list) / len(total_error_stand_still_list):.4f}\")\n",
    "print(f\"perframe score:\")\n",
    "for k, v in per_frame_error.items():\n",
    "    print(f\"{k}: {1 - sum(v) / len(v):.4f}\")\n",
    "    print(f\"{k} stand still : {1 - sum(per_frame_stand_still[k]) / len(per_frame_stand_still[k]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "800a18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if False:\n",
    "      # plt.figure(figsize=(10, 6))\n",
    "      # plt.hist(dists, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "      # plt.title('Histogram of Distances')\n",
    "      dists = np.array(dists, dtype=np.float32)\n",
    "      print(f\"stat of dists:\"\n",
    "            f\"\\n total: {len(dists)}, \"\n",
    "            f\"\\n unique: {len(np.unique(dists))}, \"\n",
    "            f\"\\n mean: {np.mean(dists)}, \"\n",
    "            f\"\\n std: {np.std(dists)}, \"\n",
    "            f\"\\n min: {np.min(dists)}, \"\n",
    "            f\"\\n max: {np.max(dists)}\")"
   ]
  }
 ],
 "metadata": {
  "fileId": "f2ee5311-2d88-471f-ae7d-82338ad3940d",
  "filePath": "/mnt/bn/nlhei-nas/liubangya/proj/vlm_proj/qwen/eval/analysis.ipynb",
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
